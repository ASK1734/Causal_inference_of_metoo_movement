{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "403e0942",
   "metadata": {},
   "source": [
    "### import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7cf2f407-5aa5-4659-ab15-69e6d55c4a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Trends Anchor Bank. The purpose of the library is to normalize Google Trends data to make it more comparable over time and across different queries.\n",
    "import gtab \n",
    "import pandas as pd\n",
    "import time \n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf02e5f",
   "metadata": {},
   "source": [
    "### Create Anchor Bank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95862eb9",
   "metadata": {},
   "source": [
    "### What is an Anchor Bank?\n",
    "\n",
    "#### Collection of Stable Search Terms:\n",
    "- An **anchor bank** is a set of search terms that are known to have relatively stable and consistent search volumes over time. These terms serve as a benchmark or reference point.\n",
    "\n",
    "#### Normalization Tool:\n",
    "- The purpose of the anchor bank is to provide a way to **normalize Google Trends data**. Google Trends gives search interest data on a relative scale (0 to 100), where 100 represents the peak popularity of the term for the specified region and time period. This relativity makes it difficult to compare different search terms directly or to analyze the same term across different time periods.\n",
    "\n",
    "#### Calibration Reference:\n",
    "- By comparing your terms of interest to these anchor terms, you can calibrate the relative search interest data to a more absolute scale. This process allows for more accurate comparisons across different search terms and timeframes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9fcd2d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using directory '/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab'\n",
      "Active anchorbank changed to: google_anchorbank_geo=_timeframe=2019-01-01 2020-08-01.tsv\n",
      "\n",
      "Active anchorbank changed to: google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  creates an instance of GTAB called t\n",
    "t = gtab.GTAB()\n",
    "#  setting a specific timeframe\n",
    "t.set_options(pytrends_config = {\"timeframe\": \"2015-12-31 2020-12-31\"})\n",
    "\n",
    "# Comment out the following line if the anchor bank has already been created\n",
    "# t.create_anchorbank()\n",
    "\n",
    "# specify which anchor bank file the GTAB instance (t) should use for normalizing Google Trends data.\n",
    "t.set_active_gtab(\"google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376de677",
   "metadata": {},
   "source": [
    "### Develop a calibrate function that employs GTAB for querying and standardizing trend data for each individual (victim/predator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4ee1aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch process a list of search terms through GTAB, standardize the format of the resulting data\n",
    "\n",
    "def calibrate(nameList, result):\n",
    "    for name in nameList:\n",
    "        # Normally, this method should return a DataFrame containing Google Trends data.\n",
    "        query = t.new_query(name)\n",
    "        #print(query)\n",
    "        if type(query) == int:\n",
    "            print(f'This name {name} is weird')\n",
    "            #temp_df = pd.DataFrame({name: [pd.NA]})\n",
    "            #result.append(temp_df)\n",
    "        else:\n",
    "            query = query.rename(columns={\"max_ratio\": name}).drop(['max_ratio_hi', 'max_ratio_lo'], axis=1)\n",
    "            result.append(query)\n",
    "        \n",
    "        # prevent google stop us from getting the data, seems to be useless\n",
    "        time.sleep(5)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "868c161f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Melissa Schuman'\n",
      "New query calibrated!\n"
     ]
    }
   ],
   "source": [
    "query = t.new_query('Melissa Schuman')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd8e146",
   "metadata": {},
   "source": [
    "### develop a split list function to split the big list into smaller list to prevent maxtryout problem for pytrends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "445da2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_list(input_list, size):\n",
    "    \"\"\"Split a list into smaller lists of a given size.\"\"\"\n",
    "    sublist = []\n",
    "    for i in range(0, len(input_list), size):\n",
    "        sublist.append(input_list[i:i + size])\n",
    "    return sublist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2218caa",
   "metadata": {},
   "source": [
    "### Get predator trend data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6993c870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Sean Hannity'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Eric Bolling'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Charles Payne'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Harry Knowles'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Lockhart Steele'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Knight Landesman'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Michael Hafford'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Jann Wenner'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Vince Ingenito'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Matt Lauer'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'John Hockenberry'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Donovan McNabb'\n",
      "Keyword Donovan McNabb is bad!\n",
      "This name Donovan McNabb is weird\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Jonathan Schwartz'\n",
      "Keyword Jonathan Schwartz is bad!\n",
      "This name Jonathan Schwartz is weird\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Don Hazen'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Mike Germano'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'H. Brandt Ayers'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Robert Moore'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Antonin Kratochvil'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Nick Sauer'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Mel Watt'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Harvey Weinstein'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Eric Schneiderman'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Clay Johnson'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Cristina Garcia'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Jeffrey Klein'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Corey Lewandowski'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Bobby Scott'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Ed Murray'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Dan Johnson'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Steven Wilder Striegel'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Chase Finlay'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Asia Argento'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Rick Day'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Morgan Freeman'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Boyd Tinsley'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Ameer Vann'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'John Kricfalusi'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Richard DeVaul'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Sam Isaly'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Robert Scoble'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Dave McClure'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Travis Kalanick'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Avital Ronell'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Mark Mellor'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'William Jacoby'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Robert Reece'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Jorge Dominguez'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Sean Hutchison'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Brent Hamilton'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Phillip Deitrich'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'John Kenneally'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Roger Ailes'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Bill O'Reilly'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Roy Price'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Andy Signore'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Donald Trump'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Christina Seafort'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Adam Venit'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Albert J. Alvarez'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Albert Schultz'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Alec Klein'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Alex Jones'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Alex Kozinski'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Andre Passos'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Andrea Ramsey'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Andy Henry'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Andy Savage'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Aziz Ansari'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Barry Lubin'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Ben Affleck'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Ben Vereen'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Benton Strong'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Bill Hybels'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Blake Farenthold'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Bob Weinstein'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Borris Miles'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Carlos Uresti'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Brett Kavanaugh'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Brett Ratner'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Mario Testino'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Bruce Weber'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Bryan Singer'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Calvin Smyre'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Francisco Ayala'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Roland G. Fryer, Jr.'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'George Tyndall'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'William Strampel'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Caleb Jennings'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Charlie Walk'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Russell Simmons'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Chris Hardwick'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Chris Sacca'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Marc Canter'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Jose De Dios'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Pavel Curda'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Justin Caldbeck'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Christian Rodriguez'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Cristiano Ronaldo'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Curtis Hill'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Dan Harmon'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Daniel Handler'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'David Blaine'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'David Copperfield'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'David Keyes'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'David Marchant'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Dustin Hoffman'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Dustin Marshall'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Ed Westwick'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Eddie Berganza'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Eric Bauman'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Erick Guerrero'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Ethan Kath'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Gary Goddard'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Geoffrey Rush'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'George H.W. Bush'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'George Takei'\n",
      "Keyword George Takei is bad!\n",
      "This name George Takei is weird\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Leon Wieseltier'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Max Ogden'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Hadrian Belove'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Shadie Elnashai'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Israel Horovitz'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'James Levine'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'James Toback'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Jeff Kruse'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Jeffrey Tambor'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Jeremy Piven'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Jeremy Tooker'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Jesse Lacey'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Joel Kramer'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'John Besh'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Junot Diaz'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Kaj Larsen'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Kirt Webster'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Larry Nassar'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Les Moonves'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Mark Schwahn'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Matthew Weiner'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Michael Douglas'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Mike Isabella'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Mohamed Muqtar'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Murray Miller'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Nick Carter'\n",
      "New query calibrated!\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('victim_list_victim1.xlsx', sheet_name='Ait')\n",
    "predator = df['predator'].drop_duplicates()\n",
    "predator = predator.reset_index().drop(['index'], axis=1)\n",
    "predator = predator['predator'].tolist() \n",
    "\n",
    "\n",
    "predator_sublists = split_list(predator, 30)\n",
    "\n",
    "\n",
    "count_sublist = 0\n",
    "for sublist in predator_sublists:\n",
    "\n",
    "    count_sublist+=1\n",
    "    pList=[]\n",
    "    calibrate(sublist, pList)\n",
    "    #print(pList)\n",
    "    pName = pList[0]\n",
    "\n",
    "    for i in range(len(pList)):\n",
    "        #print(i)\n",
    "        if i != 0:\n",
    "            pName = pd.concat([pName, pList[i]], axis=1)\n",
    "    pName\n",
    "\n",
    "    pName.to_csv(f'rawdata/predator{count_sublist}.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1a8954",
   "metadata": {},
   "source": [
    "### get victim trend data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc5df4e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query ' Stephanie Sinclair'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Lina Botero'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Andrea Sarcos'\n",
      "Keyword Andrea Sarcos is bad!\n",
      "This name Andrea Sarcos is weird\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Isadora Romero'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Federica Gonzalez'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Carmela Perez'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Sarah Pabst'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Violeta Capasso'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Kathryn Mayorga'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Candelaria Reardon'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Gabrielle McLemore'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Niki DaSilva'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Megan Ganz'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Kate Messner'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Rosanne Parry'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Angie Manfredi'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Natasha Prince'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Brittney Lewis'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Julia Salazar'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Shayndi Raice'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Jane Willenbring'\n",
      "Keyword Jane Willenbring is bad!\n",
      "This name Jane Willenbring is weird\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Deborah Doe'\n",
      "Keyword Deborah Doe is bad!\n",
      "This name Deborah Doe is weird\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Hillary Tulley'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Anna Graham Hunter'\n",
      "Keyword Anna Graham Hunter is bad!\n",
      "This name Anna Graham Hunter is weird\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Cori Thomas'\n",
      "Keyword Cori Thomas is bad!\n",
      "This name Cori Thomas is weird\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Melissa Kester'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Abby Weems'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Kristina Cohen'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Rachel Eck'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Aurlie Wynn'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Liz Gehrlein Marsham'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Joan Hilty'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Janelle Asselin'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Grace Leekley'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Kate Earley'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Allan Acevedo'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Karissa Fenwick'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Alice Glass'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Anthony Edwards'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Yael Stone'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Eryn Jean Norvill'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Heather Lind'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Jordana Grolnick'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Christina Baker Kline'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Amanda Staples'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Scott Brunton'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Michelle Cottle'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Sarah Wildman'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Jessica Lord'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Niniane Wang'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Susan Ho'\n",
      "Keyword Susan Ho is bad!\n",
      "This name Susan Ho is weird\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Leiti Hsu'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Christina Poppy'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Karina Chacham'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Mario Munoz'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Hayley Pogue'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Elle OBrien'\n",
      "Keyword Elle OBrien is bad!\n",
      "This name Elle OBrien is weird\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Jackie Gomez'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Maddie Corman'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Jocelyn Meinhardt'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Frdrique Giffard'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Maia Ermansons'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Kathleen Nickels'\n",
      "Keyword Kathleen Nickels is bad!\n",
      "This name Kathleen Nickels is weird\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Elizabeth Dann'\n",
      "Keyword Elizabeth Dann is bad!\n",
      "This name Elizabeth Dann is weird\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Laura Crook'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Kim Senko'\n",
      "Keyword Kim Senko is bad!\n",
      "This name Kim Senko is weird\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Jana Mestecky'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Chris Brown'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'James Lestock'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Ashok Pai'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Albin Ifsich'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Ardienne LaValley'\n",
      "Keyword Ardienne LaValley is bad!\n",
      "This name Ardienne LaValley is weird\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Louise Post'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Karen Sklaire'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Anna Scott'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Sari Kamin'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Terri Conn'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Chantal Cousineau'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Sara Gelser'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Trace Lysette'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Van Barnes'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Ariane Bellamar'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Cobrina Grieco'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Megan Kepnach'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Karley Webb'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Nicole Garey'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Emily Driskill'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Eliza Dushku'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Madie Robison'\n",
      "Keyword Madie Robison is bad!\n",
      "This name Madie Robison is weird\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Vy Linh Ky'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Lindsey Reynolds'\n",
      "Keyword Lindsey Reynolds is bad!\n",
      "This name Lindsey Reynolds is weird\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Zinzi Clemmons'\n",
      "Keyword Zinzi Clemmons is bad!\n",
      "This name Zinzi Clemmons is weird\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Monica Byrne'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Phoebe Barghouty'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Austin Rick'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Aly Raisman'\n",
      "Keyword Aly Raisman is bad!\n",
      "This name Aly Raisman is weird\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'McKayla Maroney '\n",
      "Keyword McKayla Maroney  is bad!\n",
      "This name McKayla Maroney  is weird\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Jamie Dantzscher'\n",
      "Keyword Jamie Dantzscher is bad!\n",
      "This name Jamie Dantzscher is weird\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Jeanette Antolin'\n",
      "Keyword Jeanette Antolin is bad!\n",
      "This name Jeanette Antolin is weird\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Rachael Denhollander'\n",
      "Keyword Rachael Denhollander is bad!\n",
      "This name Rachael Denhollander is weird\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Kamerin Moore'\n",
      "Keyword Kamerin Moore is bad!\n",
      "This name Kamerin Moore is weird\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Illeana Douglas'\n",
      "Keyword Illeana Douglas is bad!\n",
      "This name Illeana Douglas is weird\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Janet Jones'\n",
      "Keyword Janet Jones is bad!\n",
      "This name Janet Jones is weird\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Christine Peters'\n",
      "Keyword Christine Peters is bad!\n",
      "This name Christine Peters is weird\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Dinah Kirgo'\n",
      "Keyword Dinah Kirgo is bad!\n",
      "This name Dinah Kirgo is weird\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Julie Kirgo'\n",
      "Keyword Julie Kirgo is bad!\n",
      "This name Julie Kirgo is weird\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Audrey Wauchope'\n",
      "Keyword Audrey Wauchope is bad!\n",
      "This name Audrey Wauchope is weird\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Kater Gordon'\n",
      "Keyword Kater Gordon is bad!\n",
      "This name Kater Gordon is weird\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Susan Braudy'\n",
      "Keyword Susan Braudy is bad!\n",
      "This name Susan Braudy is weird\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Chloe Caras'\n",
      "Keyword Chloe Caras is bad!\n",
      "This name Chloe Caras is weird\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Sara Hancock'\n",
      "Keyword Sara Hancock is bad!\n",
      "This name Sara Hancock is weird\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Layshia Clarendon'\n",
      "Keyword Layshia Clarendon is bad!\n",
      "This name Layshia Clarendon is weird\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Aurora Perrineau'\n",
      "Keyword Aurora Perrineau is bad!\n",
      "This name Aurora Perrineau is weird\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Melissa Schuman'\n",
      "Keyword Melissa Schuman is bad!\n",
      "This name Melissa Schuman is weird\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_excel('victim_list_victim1.xlsx', sheet_name='Rj')\n",
    "victim = df1['victim'].drop_duplicates()\n",
    "victim = victim.reset_index().drop(['index'], axis=1)\n",
    "victim = victim['victim'].tolist() \n",
    "#victim = victim.tolist()\n",
    "\n",
    "victim_sublists = split_list(victim, 30)\n",
    "\n",
    "\n",
    "count_sublist = 0\n",
    "for sublist in victim_sublists[7:]:\n",
    "\n",
    "    count_sublist+=1\n",
    "    vList=[]\n",
    "    calibrate(sublist, vList)\n",
    "    #print(pList)\n",
    "    vName = vList[0]\n",
    "\n",
    "    for i in range(len(vList)):\n",
    "        #print(i)\n",
    "        if i != 0:\n",
    "            vName = pd.concat([vName, vList[i]], axis=1)\n",
    "    vName\n",
    "\n",
    "    vName.to_csv(f'rawdata/victim{count_sublist}.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ff970d",
   "metadata": {},
   "source": [
    "### combine all predator's sublist csv into one big dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dcc01b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/2325958608.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predator_all[p] = monthly_sum_df[p]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/2325958608.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predator_all[p] = monthly_sum_df[p]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/2325958608.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predator_all[p] = monthly_sum_df[p]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/2325958608.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predator_all[p] = monthly_sum_df[p]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/2325958608.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predator_all[p] = monthly_sum_df[p]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/2325958608.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predator_all[p] = monthly_sum_df[p]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/2325958608.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predator_all[p] = monthly_sum_df[p]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/2325958608.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predator_all[p] = monthly_sum_df[p]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/2325958608.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predator_all[p] = monthly_sum_df[p]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/2325958608.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predator_all[p] = monthly_sum_df[p]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/2325958608.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predator_all[p] = monthly_sum_df[p]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/2325958608.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predator_all[p] = monthly_sum_df[p]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/2325958608.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predator_all[p] = monthly_sum_df[p]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/2325958608.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predator_all[p] = monthly_sum_df[p]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/2325958608.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predator_all[p] = monthly_sum_df[p]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/2325958608.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predator_all[p] = pd.NA\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/2325958608.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predator_all[p] = monthly_sum_df[p]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/2325958608.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predator_all[p] = monthly_sum_df[p]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/2325958608.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predator_all[p] = monthly_sum_df[p]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/2325958608.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predator_all[p] = monthly_sum_df[p]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/2325958608.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predator_all[p] = monthly_sum_df[p]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/2325958608.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predator_all[p] = monthly_sum_df[p]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/2325958608.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predator_all[p] = monthly_sum_df[p]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/2325958608.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predator_all[p] = monthly_sum_df[p]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/2325958608.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predator_all[p] = monthly_sum_df[p]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/2325958608.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predator_all[p] = monthly_sum_df[p]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/2325958608.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predator_all[p] = monthly_sum_df[p]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/2325958608.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predator_all[p] = monthly_sum_df[p]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/2325958608.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predator_all[p] = monthly_sum_df[p]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/2325958608.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predator_all[p] = monthly_sum_df[p]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/2325958608.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predator_all[p] = monthly_sum_df[p]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/2325958608.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predator_all[p] = monthly_sum_df[p]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/2325958608.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predator_all[p] = monthly_sum_df[p]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/2325958608.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predator_all[p] = monthly_sum_df[p]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/2325958608.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predator_all[p] = monthly_sum_df[p]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/2325958608.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predator_all[p] = monthly_sum_df[p]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/2325958608.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predator_all[p] = monthly_sum_df[p]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/2325958608.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predator_all[p] = monthly_sum_df[p]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/2325958608.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predator_all[p] = monthly_sum_df[p]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/2325958608.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predator_all[p] = monthly_sum_df[p]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/2325958608.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predator_all[p] = monthly_sum_df[p]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/2325958608.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  predator_all[p] = monthly_sum_df[p]\n"
     ]
    }
   ],
   "source": [
    "predator_all = pd.DataFrame()\n",
    "predator1 = pd.read_csv(\"/Users/chenshaokai/Desktop///me_too/Alan/google trend & victim list/predator1.csv\")\n",
    "predator2 = pd.read_csv(\"/Users/chenshaokai/Desktop///me_too/Alan/google trend & victim list/predator2.csv\")\n",
    "predator3 = pd.read_csv(\"/Users/chenshaokai/Desktop///me_too/Alan/google trend & victim list/predator3.csv\")\n",
    "predator4 = pd.read_csv(\"/Users/chenshaokai/Desktop///me_too/Alan/google trend & victim list/predator4.csv\")\n",
    "predator5 = pd.read_csv(\"/Users/chenshaokai/Desktop///me_too/Alan/google trend & victim list/predator5.csv\")\n",
    "\n",
    "\n",
    "\n",
    "# Merge the DataFrames on the 'date' column\n",
    "combined_df = pd.merge(predator1, predator2, on='date', how='outer')\n",
    "combined_df = pd.merge(combined_df, predator3, on='date', how='outer')\n",
    "combined_df = pd.merge(combined_df, predator4, on='date', how='outer')\n",
    "combined_df = pd.merge(combined_df, predator5, on='date', how='outer')\n",
    "\n",
    "# Convert 'date' column to datetime if it's not already\n",
    "combined_df['date'] = pd.to_datetime(combined_df['date'])\n",
    "\n",
    "# Create a new column for year-month\n",
    "combined_df['year_month'] = combined_df['date'].dt.strftime('%Y-%m')\n",
    "\n",
    "# Group by the 'year_month' column and sum up the values\n",
    "monthly_sum_df = combined_df.groupby('year_month').sum()\n",
    "\n",
    "\n",
    "for p in predator:\n",
    "    if p in monthly_sum_df:\n",
    "        predator_all[p] = monthly_sum_df[p]\n",
    "    else:\n",
    "        predator_all[p] = pd.NA\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5234ed7a",
   "metadata": {},
   "source": [
    "### The column in predator that include NA\n",
    "For some reason, when you use gtab to search for the first time, some name will show \"bad keyword error\", so I list out all the column that include NA and rerun again. For the Fake NA will fill with the correct value and the real NA will remain NA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "51b9a090",
   "metadata": {},
   "outputs": [],
   "source": [
    "predator_NA = []\n",
    "for column in predator_all.columns:\n",
    "    if predator_all[column].isna().any():\n",
    "        predator_NA.append(column)\n",
    "\n",
    "#predator_NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfed58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pList2 = []\n",
    "calibrate(predator_NA, pList2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "e5a39f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(pList2)):\n",
    "    predator_NA_df = pList2[i].reset_index()\n",
    "    \n",
    "    # Convert 'date' column to datetime if it's not already\n",
    "    predator_NA_df['date'] = pd.to_datetime(predator_NA_df['date'])\n",
    "\n",
    "    # Create a new column for year-month\n",
    "    predator_NA_df['year_month'] = predator_NA_df['date'].dt.strftime('%Y-%m')\n",
    "\n",
    "    # Group by the 'year_month' column and sum up the values\n",
    "    predator_NA_sum_df = predator_NA_df.groupby('year_month').sum()\n",
    "    \n",
    "    predator_all[predator_NA_sum_df.columns[0]] = predator_NA_sum_df[predator_NA_sum_df.columns[0]]\n",
    "\n",
    "predator_all.to_csv(\"/Users/chenshaokai/Desktop///me_too/Alan/google trend & victim list/rawdata/predator_all.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c55de63",
   "metadata": {},
   "source": [
    "### combine all victim's sublist csv into one big dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b9405c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = pd.NA\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = pd.NA\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = pd.NA\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = pd.NA\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = pd.NA\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = pd.NA\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = pd.NA\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = pd.NA\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = pd.NA\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = pd.NA\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = pd.NA\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = pd.NA\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = pd.NA\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = pd.NA\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = pd.NA\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = monthly_sum_df[v]\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = pd.NA\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = pd.NA\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = pd.NA\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = pd.NA\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = pd.NA\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = pd.NA\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = pd.NA\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = pd.NA\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = pd.NA\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = pd.NA\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = pd.NA\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = pd.NA\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = pd.NA\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = pd.NA\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = pd.NA\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = pd.NA\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = pd.NA\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = pd.NA\n",
      "/var/folders/b4/tzgj0xts7l3fbrls_kjwdvkm0000gn/T/ipykernel_17275/1371686011.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  victim_all[v] = pd.NA\n"
     ]
    }
   ],
   "source": [
    "victim_all = pd.DataFrame()\n",
    "victim1 = pd.read_csv(\"/Users/chenshaokai/Desktop///me_too/Alan/google trend & victim list/victim1.csv\")\n",
    "victim2 = pd.read_csv(\"/Users/chenshaokai/Desktop///me_too/Alan/google trend & victim list/victim2.csv\")\n",
    "victim3 = pd.read_csv(\"/Users/chenshaokai/Desktop///me_too/Alan/google trend & victim list/victim3.csv\")\n",
    "victim4 = pd.read_csv(\"/Users/chenshaokai/Desktop///me_too/Alan/google trend & victim list/victim4.csv\")\n",
    "victim5 = pd.read_csv(\"/Users/chenshaokai/Desktop///me_too/Alan/google trend & victim list/victim5.csv\")\n",
    "victim6 = pd.read_csv(\"/Users/chenshaokai/Desktop///me_too/Alan/google trend & victim list/victim6.csv\")\n",
    "victim7 = pd.read_csv(\"/Users/chenshaokai/Desktop///me_too/Alan/google trend & victim list/victim7.csv\")\n",
    "victim8 = pd.read_csv(\"/Users/chenshaokai/Desktop///me_too/Alan/google trend & victim list/victim8.csv\")\n",
    "victim9 = pd.read_csv(\"/Users/chenshaokai/Desktop///me_too/Alan/google trend & victim list/victim9.csv\")\n",
    "victim10 = pd.read_csv(\"/Users/chenshaokai/Desktop///me_too/Alan/google trend & victim list/victim10.csv\")\n",
    "victim11 = pd.read_csv(\"/Users/chenshaokai/Desktop///me_too/Alan/google trend & victim list/victim11.csv\")\n",
    "\n",
    "\n",
    "\n",
    "# Merge the DataFrames on the 'date' column\n",
    "combined_df = pd.merge(victim1, victim2, on='date', how='outer')\n",
    "combined_df = pd.merge(combined_df, victim3, on='date', how='outer')\n",
    "combined_df = pd.merge(combined_df, victim4, on='date', how='outer')\n",
    "combined_df = pd.merge(combined_df, victim5, on='date', how='outer')\n",
    "combined_df = pd.merge(combined_df, victim6, on='date', how='outer')\n",
    "combined_df = pd.merge(combined_df, victim7, on='date', how='outer')\n",
    "combined_df = pd.merge(combined_df, victim8, on='date', how='outer')\n",
    "combined_df = pd.merge(combined_df, victim9, on='date', how='outer')\n",
    "combined_df = pd.merge(combined_df, victim10, on='date', how='outer')\n",
    "combined_df = pd.merge(combined_df, victim11, on='date', how='outer')\n",
    "\n",
    "# Convert 'date' column to datetime if it's not already\n",
    "combined_df['date'] = pd.to_datetime(combined_df['date'])\n",
    "\n",
    "# Create a new column for year-month\n",
    "combined_df['year_month'] = combined_df['date'].dt.strftime('%Y-%m')\n",
    "\n",
    "# Group by the 'year_month' column and sum up the values\n",
    "monthly_sum_df = combined_df.groupby('year_month').sum()\n",
    "\n",
    "for v in victim:\n",
    "    if v in monthly_sum_df:\n",
    "        victim_all[v] = monthly_sum_df[v]\n",
    "    else:\n",
    "        victim_all[v] = pd.NA\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb553db2",
   "metadata": {},
   "source": [
    "### The column in victim that include NA\n",
    "For some reason, when you use gtab to search for the first time, some name will show \"bad keyword error\", so I list out all the column that include NA and rerun again. For the Fake NA will fill with the correct value and the real NA will remain NA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b99fab16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Suki Kim',\n",
       " 'Katherine OConnell',\n",
       " 'ShanTernera Williams',\n",
       " 'Sara Rabuse',\n",
       " 'Mary Frances Pulizzi',\n",
       " 'Wendy Miller',\n",
       " 'Jessica Leeds',\n",
       " 'Naomi R. Shatz',\n",
       " 'Andrea Sarcos',\n",
       " 'Jane Willenbring',\n",
       " 'Deborah Doe',\n",
       " 'Anna Graham Hunter',\n",
       " 'Cori Thomas',\n",
       " 'Susan Ho\\xa0',\n",
       " 'Elle OBrien',\n",
       " 'Kathleen Nickels',\n",
       " 'Elizabeth Dann',\n",
       " 'Kim Senko',\n",
       " 'Ardienne LaValley',\n",
       " 'Madie Robison',\n",
       " 'Lindsey Reynolds',\n",
       " 'Zinzi Clemmons',\n",
       " 'Aly Raisman',\n",
       " 'McKayla Maroney ',\n",
       " 'Jamie Dantzscher',\n",
       " 'Jeanette Antolin',\n",
       " 'Rachael Denhollander',\n",
       " 'Kamerin Moore',\n",
       " 'Illeana Douglas',\n",
       " 'Janet Jones',\n",
       " 'Christine Peters',\n",
       " 'Dinah Kirgo',\n",
       " 'Julie Kirgo',\n",
       " 'Audrey Wauchope',\n",
       " 'Kater Gordon',\n",
       " 'Susan Braudy',\n",
       " 'Chloe Caras',\n",
       " 'Sara Hancock',\n",
       " 'Layshia Clarendon',\n",
       " 'Aurora Perrineau',\n",
       " 'Melissa Schuman']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "victim_NA =[]\n",
    "for column in victim_all.columns:\n",
    "    if victim_all[column].isna().any():\n",
    "        victim_NA.append(column)\n",
    "\n",
    "victim_NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "36cba1f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Suki Kim'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Katherine OConnell'\n",
      "Keyword Katherine OConnell is bad!\n",
      "This name Katherine OConnell is weird\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'ShanTernera Williams'\n",
      "Keyword ShanTernera Williams is bad!\n",
      "This name ShanTernera Williams is weird\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Sara Rabuse'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Mary Frances Pulizzi'\n",
      "Keyword Mary Frances Pulizzi is bad!\n",
      "This name Mary Frances Pulizzi is weird\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Wendy Miller'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Jessica Leeds'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Naomi R. Shatz'\n",
      "Keyword Naomi R. Shatz is bad!\n",
      "This name Naomi R. Shatz is weird\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Andrea Sarcos'\n",
      "Keyword Andrea Sarcos is bad!\n",
      "This name Andrea Sarcos is weird\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Jane Willenbring'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Deborah Doe'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Anna Graham Hunter'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Cori Thomas'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Susan Ho'\n",
      "Keyword Susan Ho is bad!\n",
      "This name Susan Ho is weird\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Elle OBrien'\n",
      "Keyword Elle OBrien is bad!\n",
      "This name Elle OBrien is weird\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Kathleen Nickels'\n",
      "Keyword Kathleen Nickels is bad!\n",
      "This name Kathleen Nickels is weird\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Elizabeth Dann'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Kim Senko'\n",
      "Keyword Kim Senko is bad!\n",
      "This name Kim Senko is weird\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Ardienne LaValley'\n",
      "Keyword Ardienne LaValley is bad!\n",
      "This name Ardienne LaValley is weird\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Madie Robison'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Lindsey Reynolds'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Zinzi Clemmons'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Aly Raisman'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'McKayla Maroney '\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Jamie Dantzscher'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Jeanette Antolin'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Rachael Denhollander'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Kamerin Moore'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Illeana Douglas'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Janet Jones'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Christine Peters'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Dinah Kirgo'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Julie Kirgo'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Audrey Wauchope'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Kater Gordon'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Susan Braudy'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Chloe Caras'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Sara Hancock'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Layshia Clarendon'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Aurora Perrineau'\n",
      "New query calibrated!\n",
      "Using /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gtab/output/google_anchorbanks/google_anchorbank_geo=_timeframe=2016-06-30 2018-12-31.tsv\n",
      "New query 'Melissa Schuman'\n",
      "New query calibrated!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[            Suki Kim\n",
       " date                \n",
       " 2016-07-03      0.02\n",
       " 2016-07-10      0.02\n",
       " 2016-07-17      0.01\n",
       " 2016-07-24      0.00\n",
       " 2016-07-31      0.01\n",
       " ...              ...\n",
       " 2018-12-02      0.01\n",
       " 2018-12-09      0.00\n",
       " 2018-12-16      0.00\n",
       " 2018-12-23      0.00\n",
       " 2018-12-30      0.00\n",
       " \n",
       " [131 rows x 1 columns],\n",
       "             Sara Rabuse\n",
       " date                   \n",
       " 2016-07-03     0.000000\n",
       " 2016-07-10     0.000000\n",
       " 2016-07-17     0.000000\n",
       " 2016-07-24     0.000000\n",
       " 2016-07-31     0.000000\n",
       " ...                 ...\n",
       " 2018-12-02     0.000000\n",
       " 2018-12-09     0.000000\n",
       " 2018-12-16     0.007598\n",
       " 2018-12-23     0.021781\n",
       " 2018-12-30     0.000000\n",
       " \n",
       " [131 rows x 1 columns],\n",
       "             Wendy Miller\n",
       " date                    \n",
       " 2016-07-03      0.019166\n",
       " 2016-07-10      0.012321\n",
       " 2016-07-17      0.004107\n",
       " 2016-07-24      0.013690\n",
       " 2016-07-31      0.002738\n",
       " ...                  ...\n",
       " 2018-12-02      0.013690\n",
       " 2018-12-09      0.005476\n",
       " 2018-12-16      0.012321\n",
       " 2018-12-23      0.004107\n",
       " 2018-12-30      0.016428\n",
       " \n",
       " [131 rows x 1 columns],\n",
       "             Jessica Leeds\n",
       " date                     \n",
       " 2016-07-03            0.0\n",
       " 2016-07-10            0.0\n",
       " 2016-07-17            0.0\n",
       " 2016-07-24            0.0\n",
       " 2016-07-31            0.0\n",
       " ...                   ...\n",
       " 2018-12-02            0.0\n",
       " 2018-12-09            0.0\n",
       " 2018-12-16            0.0\n",
       " 2018-12-23            0.0\n",
       " 2018-12-30            0.0\n",
       " \n",
       " [131 rows x 1 columns],\n",
       "             Jane Willenbring\n",
       " date                        \n",
       " 2016-07-03          0.000000\n",
       " 2016-07-10          0.000000\n",
       " 2016-07-17          0.000000\n",
       " 2016-07-24          0.000000\n",
       " 2016-07-31          0.000000\n",
       " ...                      ...\n",
       " 2018-12-02          0.002738\n",
       " 2018-12-09          0.002738\n",
       " 2018-12-16          0.000000\n",
       " 2018-12-23          0.000000\n",
       " 2018-12-30          0.000000\n",
       " \n",
       " [131 rows x 1 columns],\n",
       "             Deborah Doe\n",
       " date                   \n",
       " 2016-07-03     0.000000\n",
       " 2016-07-10     0.000000\n",
       " 2016-07-17     0.000000\n",
       " 2016-07-24     0.000000\n",
       " 2016-07-31     0.005572\n",
       " ...                 ...\n",
       " 2018-12-02     0.000000\n",
       " 2018-12-09     0.000000\n",
       " 2018-12-16     0.000000\n",
       " 2018-12-23     0.000000\n",
       " 2018-12-30     0.019755\n",
       " \n",
       " [131 rows x 1 columns],\n",
       "             Anna Graham Hunter\n",
       " date                          \n",
       " 2016-07-03            0.000000\n",
       " 2016-07-10            0.000000\n",
       " 2016-07-17            0.000000\n",
       " 2016-07-24            0.000000\n",
       " 2016-07-31            0.000000\n",
       " ...                        ...\n",
       " 2018-12-02            0.000000\n",
       " 2018-12-09            0.011905\n",
       " 2018-12-16            0.000000\n",
       " 2018-12-23            0.000000\n",
       " 2018-12-30            0.000000\n",
       " \n",
       " [131 rows x 1 columns],\n",
       "             Cori Thomas\n",
       " date                   \n",
       " 2016-07-03         0.00\n",
       " 2016-07-10         0.00\n",
       " 2016-07-17         0.00\n",
       " 2016-07-24         0.00\n",
       " 2016-07-31         0.00\n",
       " ...                 ...\n",
       " 2018-12-02         0.00\n",
       " 2018-12-09         0.00\n",
       " 2018-12-16         0.01\n",
       " 2018-12-23         0.00\n",
       " 2018-12-30         0.00\n",
       " \n",
       " [131 rows x 1 columns],\n",
       "             Elizabeth Dann\n",
       " date                      \n",
       " 2016-07-03        0.000000\n",
       " 2016-07-10        0.000000\n",
       " 2016-07-17        0.012663\n",
       " 2016-07-24        0.000000\n",
       " 2016-07-31        0.000000\n",
       " ...                    ...\n",
       " 2018-12-02        0.000000\n",
       " 2018-12-09        0.000000\n",
       " 2018-12-16        0.007598\n",
       " 2018-12-23        0.000000\n",
       " 2018-12-30        0.000000\n",
       " \n",
       " [131 rows x 1 columns],\n",
       "             Madie Robison\n",
       " date                     \n",
       " 2016-07-03       0.000000\n",
       " 2016-07-10       0.000000\n",
       " 2016-07-17       0.000000\n",
       " 2016-07-24       0.004107\n",
       " 2016-07-31       0.000000\n",
       " ...                   ...\n",
       " 2018-12-02       0.000000\n",
       " 2018-12-09       0.005476\n",
       " 2018-12-16       0.000000\n",
       " 2018-12-23       0.000000\n",
       " 2018-12-30       0.000000\n",
       " \n",
       " [131 rows x 1 columns],\n",
       "             Lindsey Reynolds\n",
       " date                        \n",
       " 2016-07-03          0.000000\n",
       " 2016-07-10          0.009583\n",
       " 2016-07-17          0.005476\n",
       " 2016-07-24          0.000000\n",
       " 2016-07-31          0.000000\n",
       " ...                      ...\n",
       " 2018-12-02          0.005476\n",
       " 2018-12-09          0.004107\n",
       " 2018-12-16          0.000000\n",
       " 2018-12-23          0.002738\n",
       " 2018-12-30          0.005476\n",
       " \n",
       " [131 rows x 1 columns],\n",
       "             Zinzi Clemmons\n",
       " date                      \n",
       " 2016-07-03            0.00\n",
       " 2016-07-10            0.00\n",
       " 2016-07-17            0.00\n",
       " 2016-07-24            0.00\n",
       " 2016-07-31            0.00\n",
       " ...                    ...\n",
       " 2018-12-02            0.01\n",
       " 2018-12-09            0.01\n",
       " 2018-12-16            0.00\n",
       " 2018-12-23            0.00\n",
       " 2018-12-30            0.01\n",
       " \n",
       " [131 rows x 1 columns],\n",
       "             Aly Raisman\n",
       " date                   \n",
       " 2016-07-03     1.341465\n",
       " 2016-07-10     2.682930\n",
       " 2016-07-17     0.000000\n",
       " 2016-07-24     0.000000\n",
       " 2016-07-31     1.341465\n",
       " ...                 ...\n",
       " 2018-12-02     0.000000\n",
       " 2018-12-09     0.000000\n",
       " 2018-12-16     0.000000\n",
       " 2018-12-23     0.000000\n",
       " 2018-12-30     0.000000\n",
       " \n",
       " [131 rows x 1 columns],\n",
       "             McKayla Maroney \n",
       " date                        \n",
       " 2016-07-03               1.0\n",
       " 2016-07-10               3.1\n",
       " 2016-07-17               2.3\n",
       " 2016-07-24               0.8\n",
       " 2016-07-31               1.2\n",
       " ...                      ...\n",
       " 2018-12-02               0.3\n",
       " 2018-12-09               0.2\n",
       " 2018-12-16               0.1\n",
       " 2018-12-23               0.1\n",
       " 2018-12-30               0.1\n",
       " \n",
       " [131 rows x 1 columns],\n",
       "             Jamie Dantzscher\n",
       " date                        \n",
       " 2016-07-03              0.01\n",
       " 2016-07-10              0.01\n",
       " 2016-07-17              0.01\n",
       " 2016-07-24              0.01\n",
       " 2016-07-31              0.00\n",
       " ...                      ...\n",
       " 2018-12-02              0.00\n",
       " 2018-12-09              0.00\n",
       " 2018-12-16              0.00\n",
       " 2018-12-23              0.00\n",
       " 2018-12-30              0.01\n",
       " \n",
       " [131 rows x 1 columns],\n",
       "             Jeanette Antolin\n",
       " date                        \n",
       " 2016-07-03               0.0\n",
       " 2016-07-10               0.0\n",
       " 2016-07-17               0.0\n",
       " 2016-07-24               0.0\n",
       " 2016-07-31               0.0\n",
       " ...                      ...\n",
       " 2018-12-02               0.0\n",
       " 2018-12-09               0.0\n",
       " 2018-12-16               0.0\n",
       " 2018-12-23               0.0\n",
       " 2018-12-30               0.0\n",
       " \n",
       " [131 rows x 1 columns],\n",
       "             Rachael Denhollander\n",
       " date                            \n",
       " 2016-07-03              0.000000\n",
       " 2016-07-10              0.000000\n",
       " 2016-07-17              0.000000\n",
       " 2016-07-24              0.000000\n",
       " 2016-07-31              0.000000\n",
       " ...                          ...\n",
       " 2018-12-02              0.012195\n",
       " 2018-12-09              0.158537\n",
       " 2018-12-16              0.036585\n",
       " 2018-12-23              0.012195\n",
       " 2018-12-30              0.024390\n",
       " \n",
       " [131 rows x 1 columns],\n",
       "             Kamerin Moore\n",
       " date                     \n",
       " 2016-07-03       0.008214\n",
       " 2016-07-10       0.000000\n",
       " 2016-07-17       0.000000\n",
       " 2016-07-24       0.000000\n",
       " 2016-07-31       0.000000\n",
       " ...                   ...\n",
       " 2018-12-02       0.002738\n",
       " 2018-12-09       0.000000\n",
       " 2018-12-16       0.000000\n",
       " 2018-12-23       0.000000\n",
       " 2018-12-30       0.000000\n",
       " \n",
       " [131 rows x 1 columns],\n",
       "             Illeana Douglas\n",
       " date                       \n",
       " 2016-07-03             0.03\n",
       " 2016-07-10             0.02\n",
       " 2016-07-17             0.02\n",
       " 2016-07-24             0.03\n",
       " 2016-07-31             0.02\n",
       " ...                     ...\n",
       " 2018-12-02             0.02\n",
       " 2018-12-09             0.02\n",
       " 2018-12-16             0.03\n",
       " 2018-12-23             0.01\n",
       " 2018-12-30             0.02\n",
       " \n",
       " [131 rows x 1 columns],\n",
       "             Janet Jones\n",
       " date                   \n",
       " 2016-07-03         0.08\n",
       " 2016-07-10         0.07\n",
       " 2016-07-17         0.07\n",
       " 2016-07-24         0.05\n",
       " 2016-07-31         0.06\n",
       " ...                 ...\n",
       " 2018-12-02         0.04\n",
       " 2018-12-09         0.04\n",
       " 2018-12-16         0.04\n",
       " 2018-12-23         0.04\n",
       " 2018-12-30         0.06\n",
       " \n",
       " [131 rows x 1 columns],\n",
       "             Christine Peters\n",
       " date                        \n",
       " 2016-07-03          0.004107\n",
       " 2016-07-10          0.009583\n",
       " 2016-07-17          0.013690\n",
       " 2016-07-24          0.002738\n",
       " 2016-07-31          0.013690\n",
       " ...                      ...\n",
       " 2018-12-02          0.012321\n",
       " 2018-12-09          0.005476\n",
       " 2018-12-16          0.005476\n",
       " 2018-12-23          0.005476\n",
       " 2018-12-30          0.008214\n",
       " \n",
       " [131 rows x 1 columns],\n",
       "             Dinah Kirgo\n",
       " date                   \n",
       " 2016-07-03     0.000000\n",
       " 2016-07-10     0.000000\n",
       " 2016-07-17     0.000000\n",
       " 2016-07-24     0.000000\n",
       " 2016-07-31     0.002738\n",
       " ...                 ...\n",
       " 2018-12-02     0.000000\n",
       " 2018-12-09     0.000000\n",
       " 2018-12-16     0.000000\n",
       " 2018-12-23     0.000000\n",
       " 2018-12-30     0.000000\n",
       " \n",
       " [131 rows x 1 columns],\n",
       "             Julie Kirgo\n",
       " date                   \n",
       " 2016-07-03     0.000000\n",
       " 2016-07-10     0.000000\n",
       " 2016-07-17     0.000000\n",
       " 2016-07-24     0.000000\n",
       " 2016-07-31     0.000000\n",
       " ...                 ...\n",
       " 2018-12-02     0.000000\n",
       " 2018-12-09     0.000000\n",
       " 2018-12-16     0.000000\n",
       " 2018-12-23     0.000000\n",
       " 2018-12-30     0.004559\n",
       " \n",
       " [131 rows x 1 columns],\n",
       "             Audrey Wauchope\n",
       " date                       \n",
       " 2016-07-03             0.00\n",
       " 2016-07-10             0.00\n",
       " 2016-07-17             0.00\n",
       " 2016-07-24             0.00\n",
       " 2016-07-31             0.00\n",
       " ...                     ...\n",
       " 2018-12-02             0.00\n",
       " 2018-12-09             0.01\n",
       " 2018-12-16             0.00\n",
       " 2018-12-23             0.00\n",
       " 2018-12-30             0.00\n",
       " \n",
       " [131 rows x 1 columns],\n",
       "             Kater Gordon\n",
       " date                    \n",
       " 2016-07-03          0.00\n",
       " 2016-07-10          0.00\n",
       " 2016-07-17          0.00\n",
       " 2016-07-24          0.00\n",
       " 2016-07-31          0.00\n",
       " ...                  ...\n",
       " 2018-12-02          0.00\n",
       " 2018-12-09          0.01\n",
       " 2018-12-16          0.01\n",
       " 2018-12-23          0.00\n",
       " 2018-12-30          0.00\n",
       " \n",
       " [131 rows x 1 columns],\n",
       "             Susan Braudy\n",
       " date                    \n",
       " 2016-07-03          0.00\n",
       " 2016-07-10          0.00\n",
       " 2016-07-17          0.00\n",
       " 2016-07-24          0.00\n",
       " 2016-07-31          0.01\n",
       " ...                  ...\n",
       " 2018-12-02          0.01\n",
       " 2018-12-09          0.00\n",
       " 2018-12-16          0.01\n",
       " 2018-12-23          0.00\n",
       " 2018-12-30          0.00\n",
       " \n",
       " [131 rows x 1 columns],\n",
       "             Chloe Caras\n",
       " date                   \n",
       " 2016-07-03     0.000000\n",
       " 2016-07-10     0.000000\n",
       " 2016-07-17     0.000000\n",
       " 2016-07-24     0.000000\n",
       " 2016-07-31     0.000000\n",
       " ...                 ...\n",
       " 2018-12-02     0.006845\n",
       " 2018-12-09     0.008214\n",
       " 2018-12-16     0.000000\n",
       " 2018-12-23     0.000000\n",
       " 2018-12-30     0.004107\n",
       " \n",
       " [131 rows x 1 columns],\n",
       "             Sara Hancock\n",
       " date                    \n",
       " 2016-07-03      0.013170\n",
       " 2016-07-10      0.000000\n",
       " 2016-07-17      0.000000\n",
       " 2016-07-24      0.008611\n",
       " 2016-07-31      0.000000\n",
       " ...                  ...\n",
       " 2018-12-02      0.007598\n",
       " 2018-12-09      0.000000\n",
       " 2018-12-16      0.000000\n",
       " 2018-12-23      0.000000\n",
       " 2018-12-30      0.000000\n",
       " \n",
       " [131 rows x 1 columns],\n",
       "             Layshia Clarendon\n",
       " date                         \n",
       " 2016-07-03           0.004107\n",
       " 2016-07-10           0.002738\n",
       " 2016-07-17           0.006845\n",
       " 2016-07-24           0.006845\n",
       " 2016-07-31           0.002738\n",
       " ...                       ...\n",
       " 2018-12-02           0.002738\n",
       " 2018-12-09           0.000000\n",
       " 2018-12-16           0.004107\n",
       " 2018-12-23           0.000000\n",
       " 2018-12-30           0.002738\n",
       " \n",
       " [131 rows x 1 columns],\n",
       "             Aurora Perrineau\n",
       " date                        \n",
       " 2016-07-03          0.012048\n",
       " 2016-07-10          0.012048\n",
       " 2016-07-17          0.000000\n",
       " 2016-07-24          0.012048\n",
       " 2016-07-31          0.000000\n",
       " ...                      ...\n",
       " 2018-12-02          0.385542\n",
       " 2018-12-09          0.084337\n",
       " 2018-12-16          0.024096\n",
       " 2018-12-23          0.012048\n",
       " 2018-12-30          0.012048\n",
       " \n",
       " [131 rows x 1 columns],\n",
       "             Melissa Schuman\n",
       " date                       \n",
       " 2016-07-03         0.000000\n",
       " 2016-07-10         0.000000\n",
       " 2016-07-17         0.000000\n",
       " 2016-07-24         0.000000\n",
       " 2016-07-31         0.000000\n",
       " ...                     ...\n",
       " 2018-12-02         0.090909\n",
       " 2018-12-09         0.000000\n",
       " 2018-12-16         0.000000\n",
       " 2018-12-23         0.000000\n",
       " 2018-12-30         0.045455\n",
       " \n",
       " [131 rows x 1 columns]]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vList_again = []\n",
    "calibrate(victim_NA, vList_again)\n",
    "vList_again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "259c21e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(vList_again)):\n",
    "    \n",
    "    victim_NA_df = vList_again[i].reset_index()\n",
    "    \n",
    "    # Convert 'date' column to datetime if it's not already\n",
    "    victim_NA_df['date'] = pd.to_datetime(victim_NA_df['date'])\n",
    "\n",
    "    # Create a new column for year-month\n",
    "    victim_NA_df['year_month'] = victim_NA_df['date'].dt.strftime('%Y-%m')\n",
    "\n",
    "    # Group by the 'year_month' column and sum up the values\n",
    "    victim_NA_sum_df = victim_NA_df.groupby('year_month').sum()\n",
    "    \n",
    "    victim_all[victim_NA_sum_df.columns[0]] =victim_NA_sum_df[victim_NA_sum_df.columns[0]]\n",
    "\n",
    "    #victim_all[victim_NA[i]] =victim_NA_sum_df[victim_NA[i]]\n",
    "\n",
    "victim_all.to_csv(\"/Users/chenshaokai/Desktop///me_too/Alan/google trend & victim list/rawdata/victim_all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbca0b8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
